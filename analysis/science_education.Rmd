---
title: "science change education"
author: "yy"
date: "6/2/2021"
output:
  workflowr::wflow_html:
    toc: true
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 

# 如何使用科学方法来改造教育学的研究？

教育学术研究一个很重要的目标在于解决问题？这永远是研究的起点问题？研究的起点不应当是理论，也不应当是政策规定，

## 首先，需要改造的是我们的研究问题？

我们需要更多地去关注是什么与为什么的问题，而不是应当是什么和怎么做问题？对于意义与价值的思考是哲学的问题？
提高研究问题表达的精准的程度。

举一个简单的例子，学术研究的思路的做工作的思路是不一致的？实践者可以需要解决的问题是，课后服务内容的设计是合理的？我应当提供一种什么样的课后服务内容？但是这个问题的回答则比较，对现有的已经实施的课后服务措施进行评估？找出哪些有效的，哪些是无效的？这个研究结果最终也会回答最初的问题？但是思路是不一样的。我们应当提供什么样合理的课后服务内容？我们无法或者很先验地知道哪些措施是好的，专家建议的就是好的么，政策文本中建议就是好的么？其实未必，最终还是需要实践，实践是检验可行性的重要标尺。

学术研究虽然聚焦现实问题，也是可能是一个操作性的问题，那么它会关注操作的各个细节么？比如说课后服务的实施会涉及组织者、时间、任务分工、激励措施、内容的选择与设计、实施等等诸多方面。我们是否需要关注每个细节。研究工作当然是不可以关注每一个细节的。那么研究要去关注什么？这就需要关注这个事件中的一个核心的、关键的要素，以及操作中的核心环节。

"认识不足"，"重视不够"是教育问题存在的原因么？

### 如果用量化的思维来提问

学生学习效果的问题，

教师质量的评估，教师成长规律的认识

教育领导力的定义与测量？

教育资源的分配与使用效率问题？

## 其次，改变我们研究教育的方式？

研究都会涉及收集信息和分析信息问题？

那么如何科学地收集信息，如何表征这些信息？比如搜集信息的方式，到涉及到抽样和问卷调查的方式，当然还有就是使用行政管理数据，代表的是全样本的数据。表征信息的方式，这里面包括数字，或者文字表征方式。

改变我们的论证方式？
之前的研究，多采用形式逻辑的推理方式，归纳法、演绎的方式，或者利弊对比的分析方式，有比较法（相同和不同点），这里面有概念界定的？有特征总结描述。

而科学的研究方式，应当是用数据和事实来表明客观是什么的问题？用因果推断的技术去证实或者证伪因果，关系的问题。

## 研究结果的呈现方式也将会不一样

结果的呈现，表现对现实的精准描述，对未来的准确预测，对作用机制的准确分析。

## 概率与统计之间是一种什么样的关系

以前并没有看出二者的联系，觉得它们是相对独立的知识，

概率是对可能性或者不确定性的度量。统计是基于数据对概率的估量。（对概率与统计的基本知识，还需要进一步学习，以前纯粹把他们当成一种知识来学习，接下来需要系统理解概率与统计的功能。概率与统计自身没有意义，唯有用其解决研究中的问题才有意义和价值。因此，需要把他们与回归分析、因果推断联系起来。

## 回归模型与因果推断之间的关系

以前，我对回归模型与因果推断之间的关系理解不是太透彻，觉得因果推断是更为高级和复杂的回归模型，只是模型使用对了，就是可以得出因果的论断。但是最近重新学习概率与统计的知识，和因果推断的相关研究。才发现二者的关系并不是这样的。回归模型是只是解决变量之间的数理关系，即相关性的问题，自变量的变化怎么带来因变量的变化。这种关系可是因果性，也可以是非因果性。将这种关系理解为因果关系，需要符合一定的假设，这些假设主要是关于数据是如何产生的。这里面会涉及，遗漏变量的问题，样本偏差的问题，反射因果问题。测量误差或者交互效应的问题等等。是否能够得出因果的推断主要是与这些要素有关的假设，是否成立。即主要是对数据生成过程的认识和理解，而不在于使用更为复杂的回归模型。相关回归模型只是一种工具。

## 频率学派和贝叶斯学派之间的差异

统计推断中越来越多的人提倡使用贝叶斯方法，认为这种推断更接近于我们对于真理的定义和认识真理的路径，即真理是一个可能性的结论，而不是一个确定性结论，认识真理的过程，即是通过新的数据，更新原有认知的过程，即是对原告可能性结论进一步优化的过程。
那么频率学派的推论的逻辑是怎样的呢？（需要接下来的学习，进一步总结）

## 概率与统计在教育研究的意义

量化研究方法在逐步的被用研究教育问题之中，大家都在学习一些统计学的技术和方法，进行一些标准的化的量化研究。把它当成一种认为教育现实和规律的方式。但是很少有人思考，用量化方法来表达的事实就是真实的事实，用量化的方法揭示的规律就是正的规律。我们在学习怎么接近真理的方法。但鲜有人去思考什么是真理？为什么说统计方法能够让我们去接近真理。使用量化研究方式，或者的研究方法本身背后有一些预设的。这些预设成立的情况下，量化研究的结论才是可接受的。比如研究对象是可量化的，比如教师的幸福感，学生的学生效果，教师的教学质量，学生的学生兴趣，学生的心理健康程度，校长的领导风格。这些对象是否是可测量的。其实是没有定论。量化研究另外一个重要的假设，是试图通过样本的特征和规律来揭示总体的特征和规律。这一过程会多种手段，比如说频率学派的统计推断方式，贝叶斯学派的方式，各自背后的方式是不太一样的。另外，量化研究还有一个假设是我们更多地是关注平均效应，而无法预测，甚至不去关注对于个体的效果。那么这样的研究意义在哪，而对于实践者来说，更会关注具体一个学生、或者一个学生的具体行为怎么变化，怎么干预的问题，如果我们注定无法回答个体的问题，只是揭示一个群体的特征和规律的话，那么它的意义又何在么？客观世界的丰富性，多元性，丰富性差异性是否应该关注，另外，量化推断一个非常重要的假设是，所以统计推断都是一种可能性的结论。即我们永远无法100％地肯定某一些结论是准确，只能说在很大可能或才极其是可能的某一结论是成立，可惜的是很初学量化的研究会忘记这一点。这也会涉及到一个本体论的问题，人类掌握的规律本质必须是确定的，还只是永远都一种可能性的规律。即我们永远无法知道一个事情是否成立，但是我们可以在它在多大可能下是成立的。最终的结果就是至少现有的证据证明它是成立的，我就认为它是成立，除非有相反的证据证明它不是。

以上一些想法是在看概率与统计史时引发的一些思考。这可能是量化研究方法在现实中受到一些学者的质疑背后的原因，这里面有一些方法论背后的认识论的差异问题。对于这一问题的讨论非常重要，一方面可以消解非量化研究者的质疑；一方面，也能减少初学者对量化研究方法的误用。

描述研究的意义是什么？

我们为什么知道一个特征的频数信息，男女比例的问题？入学率的问题？学历达标率的问题，4%的问题，另外，学龄人口增长率的问题。为什么我们要在意这些，还有哪些重要的比例问题我们需要在意？

现比如说我们为什么关注学生的成绩，为什么要关注平均成绩，除了关注平均成绩之外，我们还想关注什么？对教师而言，他可能关注那些最低分或者最高分的同学，低分需要重点关注，如何提高他们的成绩，而高分同学可能更多地为班级或学校争取荣誉，也给更多地给教师带来职业幸福感？

我们为什么需要关注因果？

相关性对于我们的意义在哪？

相关性的研究是铺垫性质，它本身可能没有实际的意义，但是它有助于我们进行下一步的研究。比如因果或者预测。

没有因果的预测，其意见在哪？

比如说学历对能力的作用？有两种假设，教育提高了学生能力，教育把有能力的人识别出来的。如果是前者的话，那么则具有干预的功能，让学生通过教育提高能力，但如果是后者，能力弱的人不能通过教育得以提高。但是无论是教育提高了学生能力，还是把能力高的学生筛选出来，企业用人来说意义不大，他们只要知道高学历与高能力之间的具有正相关就可以了。它的目标是把能力好的人识别出来。而不在意其能力是怎么来的。

如此说来，这也试用于本科生招生和研究生招生，我们并不在意见某一因素对学生的能力因果效应，我们只在意这一因素是否识别出来能力较强者。再拓展一下，教师招聘的问题，如果仅仅是关注新进教师的质量，那么我们找到高质量教师质量的指示变量即可。但是如果我们关注的是教师教育的质量的话，那么我们需要关注那些因素具有因果的效应。比如说人才培养方案，课程体系的设置。

## 概率与统计无处不在

比如说是否打疫苗、是否买保险、是否考研？

是否买彩票

汽车摇号，学位摇号，为什么我们觉得随机事件是公平，每一个人被命中的概率是等同的，因此，就是公平的。但是我们为什么知道每一个人的被命中的概率是等同的，这是我们想像的，还是客观存在的，比如抛掷硬币的事情，为什么我们觉得硬币朝上的概率是50％，有没有其它可能，为什么不是70％。

客观事件的发生，为什么有些事件我们会一个理论估值，但是另外一些事件我们没有一个理论的估值，比如考研成功的概率，对某一个事件效果的评估。

我们还会用数量来表达现实，

种种统计报表，数值、占比，频数。

## 概率与统计功能

描述

预测

解释

干预

## 一个新的理解统计推断的思路

统计推断的基本功能是通过样本特征来提示总体的特征。包括描述性的特征，也包括一些变量之间的关系。那么我们以何种标准来确定样本选择是能够反映整体特征，在整体不知道的情况。这可能是一个难题。但是假如如果我真的知道这个理论值的话，就可以推断样本的推测的值是不是具有代表性，或者准确。

比如说掷硬币的问题。我们知道它出现的概率是0.5。我们可以通过重复抽样来接近个概率，以此可以判断某一个硬币的准确性。这是因为我们无法知道某一个硬币某一抛掷后的结果，但是我们知道如果抛掷足够多的次数后，我们可以知道他们最终的结果。（这似乎是理解统计推断的一个好的例子，但好像又不是！）。统计推断是不知道某一变量本身的分布，但是如果无数次取值的话，那么它的的样本均值的分布是知道（中心极限定理），因为我知道样本均值的分布，所以可以计算出某一样本的均值随机出现的概率。如果这个概率是极低的，但是现在一次抽样，就获得了这个值，这说明原假设很可能是不对的。那么就是备择假设是对的。这是传统统计推断的理论基础。这样的理论推断遭到了越来越多的质疑。（我现在还不是很理解这个质疑的合理性在哪，所以要需要进一步理解贝叶斯统计推断的基本原理）。

## 回归分析时的统计推断

对参数的统计统计推断的理论基础是什么？置信区间的内涵是什么？和对变量均值的估计的理论基础是一致的么？

## 科学模型与统计模型之间的关系

一项研究首先需要有一个科学模型，即对客观世界中各要素之间关系的设想，而统计模型是以回归方程的方式来证实或者证伪这个科学模型，在一定的假设条件中。统计模型只是给科学模型提供一定的支撑，而统计模型无法完全证实科学模型的正确与否。也就是说统计模型无法独立证实科学模型。统计模型可以回答一个因素的变化，伴随着另外一个因素的变化，但是无法回答到底哪个因素是因，哪个因素是果。

认识到这一点之后，我们如何进行研究的设计，如何进行统计方法的选择。首先需要对研究的对象的微观机制进行充分的了解，因此，个案分析是必不可少的步骤。研究的规律或者认识的规律以归推理为前提，看清个案，在个案中总结其中的规律性东西。找出规律性的东西，即是形成假设的能力，也是理论创新的能力。所以理论创新的能力来自于对现实的把握。因此，研究者一定要接触现场。

（研究的专业化与现实的脱节。在学术研究的早期，研究者一般是实践者，二者是一体的，比如对教学方法的研究，可能是在这做个工作，一边工作，一边研究，所谓研究即是对自己工作的反思与总结，这种研究是以现实、现场为前提的），但是当学术研究成为一种专业的时候，很多研究者并不是实践者，那么，此时，就需要一些途径和方法，让他们对接触现实，体现现场。如果没有去接受现实，体验现场的话。那么他们的研究多半是不切实际的。比如硕士生、博士生的研究。他们一般是缺乏对现实的把握。所以对他们来说，一个巨大的障碍是如何发现有价值和有意义的问题。由此可知硕博的培养应当加强对现实问题的了解和接触。最好的途径是接触现场，其次是通过转述。

统计模型是服务于理论模型的，那么我们必须很好了解模型的适用条件和特征，这样才能有效使用这些模型。这个过程，应该将统计模型作为一种技能来年看待，即是技能就需要不断地练习，最终才能熟能生巧。才能为科学研究服务。

学习统计模型，可以遵循做中学，看中学，再在推理中学的步骤。传统的学习是在推导中学习概率与统计，先学习抽象的理论，进而将理论应用于实际问题的解决中。即先理解，后操作。但是更有利的方式可能先操作，后理解。将抽象的东西具体化，将隐藏的东西可视化，这样才能有助于理解。

## 什么是随机变量？

变量是一个可变化的量，是和常数对应的概念。随机变量是什么呢？是否是指这个变化的量中的量的变化的是随机的。比如说我们说一个班级的成绩是随机变量。但是班级里面的是确定的，不是随机的。更进一步需要追问的是，什么是随机？随机是基于实验的事件空间，即一个实验有多少可能的结果。

## 回归方程需要厘清的几个问题

其一，如果有一个xj，其与其它xj和e都不相关，但与y相关，这个变量遗漏是否对其它经的影响的估计有影响。这个是没有影响的。

其二，加入变量带来的影响，假如加入一个变量，对其变量带来影响。这有哪些可能的机制，collider
bias, mediation, comfound, 除此之外呢，还有什么更复杂的因素？

## 模型选择与数据生成过程

以前在做模型选择的时候，这里面主要是指选择线性回归，logistic 回归，multi
logistic
回归，ordinal回归，还是就是count数据的回归。基于因变量的数据类型选择不同的回归议程。现在学习熵的理论之后，才明白为什么选择这些回归。主要是这亲数值的产生过程的假设。这里面没有一个必须科学的东西的在里面。只是基于已有的信息而做出的最保守的对因变量取值的分布的假设。比如binomial,
poisson等等。这个假设是否合理，需要我们对客观现象有深刻的了解。另外，为了能更好的理解这些假设的合理性。那么必须了解这些有名的概率分布的内涵与属性。这样才能更深刻地理解回归议程。

另外一个重要的问题，真正回归的时候，其它是对epsilon的分布回归的假设，而不是针对y的假设。这个还需要进一步的理解。另外，对于系数的假设在frequentist回归方程中多数是基于t分布假设。

在理解量化研究的路上，以下数学基础是必须拥有的，概率论的知识，以前对于概率论的学习还是太少了，导致着在学习量化研究方法时，很难理解其中的一些推理。因是概率论是学习量化研究的基础。而学好概率论则需要，线性代数和微积分的知识。这是基础的的基础。接下来要利用规律时间。逐步夯实这两门知识。在学习好概率论的基础上，要学习统计推断的知识。introduction
to modern
statistics(online),使用simulation的方式讲授知识，很容易理解一些。这里面有两个流派，频率派和贝叶斯派，这两个学派的技术都要学习。在以上的基础之上，再说因果推断的知识，这包括counterfactual
and
DAG。在夯实自己在量化研究上的技术的过程中。需要采取以下三种学习模式：突击学习、长期学习和实践学习。实践学习都将业已学习的知识运用的教育问题的研究中来，今年要开始写量化研究的论文了。2022年至少要写三篇。另外，就是突击学习、最近在突击学习是概率论和贝叶斯统计推断的知识。接下来要把线性代数的知识拿起来了。

在今后的学习过程中，需要不断的做笔记，写感想，形成相关的材料集。供今后教学使用。

学习的步骤应当遵循先易后难的原则。另外, introduction to
probability　这本书是极好的，它不仅仅是讲授抽象的理论，更注重将这些抽象的理论转化成生活的语言，生活中的例子。这使得知识点易于理解，也使得知识变得有趣。statistical
rethinking这本书也是极好的，这把知识转化为可理解故事。用简单的故事，和打比方的方式讲解知识，也是很好的授课技巧。这两本书都展现了作者对知识本向理解的通透，也对知识与生活之间的关系把握的比较深刻。这是我需要学习的。rethinking这本书还有一个非常好的学习技术，就是simulation,当然itp这本书，也在强调这项技术的应用。因此，在今后的学习、教学、科研过程中也要加强这项技术的使用。

量化研究作为一项技术，需要不断的重复训练，这项技术才会熟练起来，熟练起来才会有新的突破。

在接触survival
analysis的时候发现，probability的知识真是太重要了，一定要理解概率论的知识，这是其它统计方法的基础。这个不夯实，其它很难取得进步。

预测与因果之间的关系

以前我觉得这两者是递进关系。但是要区分这两个事件的不同。预测是针对因变量而言，不管自变量的多少和指数。只要在有限的自变量的信息的情况下，可能准确的预测因变量就行。而因果关系刚探讨的是变量之间的关系问题。

就模型而言，一个能有效预测结构的模型，并不是一定揭示因果。而且一个准确的因果则可以对于未来的预测做到准备。为什么？

学术研究喜欢问为什么？即探究因果问题，一个要素的变化是否会给另一个要素带来变化。但是我们更需要思考的是预测。比如一个地区的学生总量，一个地区教师流动的数量，区域间的高考学生成绩差异，教师工资差异。一个是否考研，是否能考上，毕业生是否进入体制内？在学术研究上会有什么突破呢？现在能够想到的，预测研究作为因果研究的基础阶段，比如匹配法的使用过程中，以前使用logistic
方程对个体是否进入实验组进行测量，而现在则可以使用机器学习的方式进行更准确的预测。只要预测准确即可，并不需要了解预测使用的变量与预测结果之间的因果关系。

DAG的作用

DAG是一种很重要的表达工具。它的功能主要表现在以下方面：第一，表达理论模型，dag所代表的各种因素之间的关系与无关系，是我们对一个现象的发生与影响的种种假设；因此，他可以很好地表达我们的理论预设。第二，DAG可以有利于我们找到我们关心的一对因果关系的识别策略（identification
strategies).比如控制哪些变量需要控制，哪些变量不需要控制，如果控制一些变量会带来哪些后果。

DAG的局限

无法表达调节效应

无法表达同时效应，即A作用于B的同时，b也作用于A

无法表达
